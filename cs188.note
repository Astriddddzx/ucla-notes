
Computer Science 188 - Advanced Software Construction

http://web.cs.ucla.edu/classes/spring16/cs188-3

Paul Eggert

(1) Case studies of large programs
    - learn by reading code
    - learn by writing/changing code
      * Eggert will supply one example: GNU Emacs
        + Eggert knows it
        + it has been around for some time
        + it has multi-level abstraction
          Elisp extensions (most of Emacs) (modify Emacs by adding modules)
          C core (small but key part)
      * We pick one
        Chrome, GCC, Node.js, ...

(2) One other homework, currently undecided
    probably in micro-services area

20%    GNU Emacs case study
30%    personal case study
10%    other homework
15%    midterm (open book/notes)
25%    final exam (open book/notes)

June 5 drop-dead date, last day of instruction


Eggert lectures schedule
-------------------------
  1  intro
  1  Emacs tour
  1  regular expression
     Perl compatible regular expressions (PCRE)
     case study involves adding PRCR to Emacs
  5  micro-services
  8  continuous delivery & DevOps
  1  midterm
  2  presentations
  1  fun stuff (configuration + startup)


==============
Mar. 29, 2016
==============

--------------------------
By next time read
  Bug #23133
  Cox on RE2 (parts 1-4)
--------------------------

gzip 1.7 (2016-03-28)

--rsyncable: compressing files making gzip work better with program rsync
  rsync : operates on blocks, compares and changes only the changed parts

common in systems with 'deduplication'
file system knows what is going on and does not maintain copies but keeps
track that the copy exists

  $ cp a b
  $ ls -li a b

    247963 -rw-r-r-       193261   a
    257106 -rw-r-r-       193261   b

                   inodes
           +----+
           |   -----------------+        actual data
+---+      +----+    +----+     |    +-----+------+----+
| a -----> |    |    |    |     +--> |     |      |    |
+---+      +----+    +----+     |    +-----+------+----+
| b ---------------> |   -------+
+---+                +----+


file system will figure out that two files are the same and will not keep two
copies in order to save space

(1) since ~1990

(2) gzip.c ought to parse input and invoke zlib to do the real work
    BUT it actually has its own copy
    should we fix this problem?
    if we find a bug in either one, we would have to change both

(3) is gzip the best compression algorithm we have?
  
      0. preserves data
      1. smallest output
      2. fastest compression
      3. fastest decompression
      4. doesn't leak data
      5. uses least RAM compression
      6. uses least RAM decompression

    there isn't a single compression algorithm that dominates here
    gzip came out at right time, was free, and good 'enough'


GNU Bug 23133 (http://bugs.gnu.org/23133)
------------------------------------------
Built gzip on platform Oracle Solaris Studio 12.4 x86-64
has its own C compiler cc

  $ ./configure CC=cc CFLAGS='m64 -g'
  $ make
  $ make check

    ./gzip < gzip.doc > t    ->    dumped core

  $ dbx
  $ (dbx) where

    [1] 0x428885(--gibberish--)  <- nameless function with gibberish arguments
    [2] deflate()
    [3] zip()
    [4] treat_stdin()
    [5] main()

possibilities
  weird shared library
  lambda functions (not directly possible in the C language)


Eggert reproduced the same result on Oracle Solaris Studio 12.3

deflate() was calling longest_match

  static int
  longest_match (IPOS cur_match) {
    // C code here
  }

use gdb to disassemble 0x428885

  pushl (----)
  pushl (----)
  # reasonable instructions #
  # no ret! #

looked at source code and saw guards

  #ifndef ASMV

  static int
  longest_match (IPOS cur_match) {
    // C code here
  }

  #endif

tried to find where this came from
 
  $ grep ASMV *

    config.h #define ASMV

  $ grep -r longest_match /usr/include

  $ grep -r longest_match *

    lib/match.c: longest_match: (no x86-64 version)
    # this was inline assembly inside a C file

      #if defined(i386) || defined(__i386) || ...
        longest_match:
              pushl (....)
              pushl (....)
              ...
              ret
      #endif

here's what ./configure does

  ./configure CC=cc CFLAGS='-m64 -g'
  configure.ac  #Autoconfig input (automatically generates configure scripts)
    if
      cp lib/match.c  _match.S
      cc -E -m64 -g _match.S > _match.S  # do macro expansion
      cc -m64 -c _match.S &&
      test -f _match.o
    then
      AC_DEFINE([ASMV])
    fi

here's the part that took the longest time for Eggert to fix

  cc -m64 -E t.c
    +--------+
    | t.c    |
    +--------+
    | i386   |
    | __i386 |
    +--------+    output looked like input

  cc -m64 -E t.S  <--  preprocessable assembler
    +--------+
    | t.S    |
    +--------+
    | i386   |  -->  1
    | __i386 |  -->  __i386
    +--------+

here's how Eggert fixed the bug
added '&& !defined(__x86_64__)'

  #if (defined(i386) || defined(__i386) || ...) && !defined(__x86_64__)
    longest_match:
          pushl (....)
          pushl (....)
          ...
          ret
  #endif


What can we learn from this bug report and fix?
------------------------------------------------
(1) 'make check' is your friend

(2) asm version was originally important
    maybe remove it now!
    this has become a maintainence problem

(3) gzip should use glib

(4) must view your program at multiple levels down to the machine level code

(5) important to also have a workaround
    ./configure CC='cc -m64' CFLAGS=-g DEFS='-D NO_ASM'
    # this is a hack to skip test for ASMV
    # gcc -D NDEBUG  or  gcc -DNDEBUG

(6) dump Solaris?
         HP-UX
         AIX


this is common, ordinary in "real" software development
--------------------------------------------------------
Q: can this be taught?
A1: yes, but only by doing, and it's not academic
A2: yes, and there is a set of methods that survive technology change


Central problems of software construction
------------------------------------------
this is not software engineering
  one of the biggest problems here is getting requirements right

(1) modularity (mechanism for dividing programs)
    cannot keep program as one big piece, it simply doesn't scale
    have to keep them in manageable pieces
    we don't have a good enought handle yet on modularity

(2) abstraction (good modularity)
    not only break program into pieces but pieces are nicely orgainized
    we can build a layer between low-level hardware and high-level machine
    the line dividing this gives a pattern that is useful in solving problems

(3) flexibility/composability (ease of building/conceiving new programs)
    broken up program into pieces
    other program can substitute pieces into original to build new program
    similar to jigsaw puzzle
    modules that plug together

(4) autonomy
    want different modules to operate on own without worrying about each other
    want each piece to be manageable by a different crew
    able to run each piece without worrying about other piece
    important in cloud-based environment, keeping pieces in different 'clouds'
    even important in monolithic applications, for multi-threading

(5) portability (technology heterogeneity)
    want code to survive changes in technology wihtout changing code too much
    want application to work independent of technology

(6) scalability
    want system to work well regardless of problem size
    want amount of work to grow roughly linearly O(N) with work size
    important for scaling on the cloud
    
    vertical vs. horizonatal scale
    horizontal: just add servers
    vertical: have single server that is powerful

    scaling with code size (solution, not problem here)
    techniques to handle huge programs need to change

(7) ease of replacement
    want to avoid 'too big to fail' problem
    which means there is one huge component that is 'too big' that if it fails
    the whole program has to fail
    depends too much on one single component

(8) approachability/learnability
    can easily learn the code and program structure
    how easy to get new users
    how easy to get developers
    how easy to get operators

(9) ease of deployment (getting improvements to users)
    as we add new funcitonalities, how easy to push out fixes to all users

(10) organizational alignment
     not 'class boundaries map into behavior'
     want to match developer groups to code they write, not object behavior
     java: object hierarchy (behavior), package hierarchy (organization)
     not just ownershp but shifting development resources

(11) developers should not have to wait
     wait to checkin a new version in order to compile
     do not wait for a 'good build'
     should not be waiting in order to start developing
     give developers control over the version they use 


==============
Mar. 31, 2016
==============

Central problems
  modularity
  abstraction
  flexibility
  autonomy
  portability
  scaling
  org alignment
  ease of deployment
  ease of replacement
  developers should not have to wait

(12) ease of configuration
     easy to set things up so that it operates correctly in that environment
     should be automatic if possible
     huge problems lie in configuration errors in practice

(13) risk/stress of new releases
     about to come up with new version and not know what to do
     since new releases are so stressful and risky, do them more often

(14) debugging
     e.g. multithreaded applications (legendarily hard to debug due to race
     conditions)
     
     1. repeating bugs
     2. find the cause of the bug
     3. fixing the bug

(15) performance
     performance improvement is a form of debugging
     because bad performance is a bug


Suppose you have a big software engineering project and it keeps growing,
what can you do?

(1) hire more programmers! (doesn't scale up)
(2) hire better programmers!
(3) improve the software process
(4) improve the code itself


construction techniques you already know
-----------------------------------------
;        sequencing        a = a + 1; b = a + 2;
if       alternations
while    iteration
f(x)     functions & calls (recursion)
         classes (templates, generics) encapsulate common behavior
         protocols (derived from networking)
         introspection ('self-aware' code, program can inspect itself)
         serialization (converting to serial form)
         multithreading (synchronization) break into parallel pieces
         generators | implicit sequences
         iterators  | implicit sequences
         asynchronous funtion calls (callback, signals, asynchronous I/O)
         code libraries (dynamic linking)
         domain specific languages (mutate language to fit problem)
         dependency tracking ('make')
         version control + tracking ('git') (branching, merging, patching)

code is closely related to data
  sequencing is like struct { int x, double y }
  alternations is like union {   }
  iteration is like an array ----------
  recursion is like a tree, stack
  protocols match well to serialization
  introspection such as in Java: class Class (tells the class type)

other technology to cover
--------------------------
(1) macro processing
    #define N 1024
    case study in Emacs has several forms of macroprocessing

(2) memory profiling and debugging
    common problem in applications is memory hog chewing up too much memory
    we profile it and find the cause of such huge memory use
    Emacs has this too

(3) byte-code interpreters
    compile language into high-level byte-code
    design particular virtual machine to run the byte-code
    Emacs has this too

(4) snapshotting/checkpointing + restarting
    doing some computation, want snapshot of current state of computation
    later we can start from the current snapshot
    improve reliability of program
    Emacs has this too

(5) lazy evaluation
    write a program but the interpreter does not execute the program eagerly
    but it puts things off until it es 'forced' to execute (print)
    Haskell uses this approach

(6) junctions (Perl6)
    (a | b | c | d) & (e | f | g)
    system uses lazy evaluation
    we have short-circuit evaluation a || b || c || d

(7) static code analysis
    gcc statically analyzes code
    mundane but also focus of leading technology

(8) metaprogramming & code generating
    Emacs has this too

(9) self-modifying code
    Emacs has this too

(10) automated testing
     Emacs has this too

(11) style checking
     Emacs has this too

what we probably won't cover
-----------------------------
(1) software engineering process
(2) big data, big parallelism (don't have enough resources)


Regular Expressions
--------------------
pattern   a(b|c)*bc
string    dabbcbcbcdabc (4 different matches in same string)

pattern   b(a|b|c|d)*c
string    dabbcbcbcdabc (many more different matches in same string)


software is instructed to find best match instead of all matches
-----------------------------------------------------------------
(1) leftmost
(2) longest

how to implement R.E. search
-----------------------------
from the theory (1960s Thompson)
everything here predates Unix

                  RE      recognizer (NFA: nondeterministic finite automaton)

1 char            a       0 -a-> *1 (dot on state is a match)

concat            XY        -> x0   |      -> y0
                          0 -> x1   | -> 0 -> y1    (combine automatons)
                            -> xn   |      -> yn

alternation       X|Y     0 -> x0
                            -> x1
                            -> xn
                            -> y0
                            -> y1
                            -> yn

closure           X*


covert NFA -> DFA (deterministic finite automaton)
DFA has more states O(2^N)  ->  N: number of NFA states

how to implement a DFA?
------------------------
two dimensional array
rows are labeled by state number 
columns are labeled by input symbols

0 = no match in the array

need runtime representation for accepting state
match table of booleans indexed by state number


interpreter loop:
  int s = 1;
  do {
    c = getchar();
    s = table[s][c];
  } while (s);


table is huge
rows: O(2^N)
cols: |SIGMA| + 1
      number of symbols: ASCII     128
                         UNICODE   2^20 and more


problems in R.E. matching
--------------------------
(1) table can be too big

    use lazy evaluation!
    don't precompute entire table
    just compute a row of this table only when the state is first entered
    entries either is a state number, 0, or -1 (not yet computed)

      if (s < 0)
        s = compute(table+s)

(2) getchar() might be slow

    get from disk may have to wait for disk arm
    use buffering
    take entire string and put into RAM to access direcly
      may run out of RAM (use finite buffer if data is large)

      c = *p++  // p is ptr into string

(3) code doesn't tell us where match was

    if we find a success, we keep track of where that occurred

      match_end = NULL;
      match_start = p;
      ......
      if (match[s])
        match_end = p;

    loop continues but we have found at least one match
    will keep track if we find a longer match
    if match_end is non-NULL, then we have found a match

(4) not addressing leftmost match problem

    a. have a bigger loop that iterates over the string
    b. prepend .* to expression X

         .* X
           ^
           |
           record match_begin here


this is not efficient enough, suppose we do this

  $ grep 'c' file

easiest way in C:
  
  for (p = str; p < lim; p++) {
    if (*p == 'c')
      return 1;
  }
  return 0;

faster method than this:
  
  return !!memchr(p, 'c', lim-p);  // C standard library

    a word at a time (8 byte, say) and EXOR (^) with array of 'c'


=============
Apr. 1, 2016
=============

Goal: add Perl REs to Emacs
Initial hello to get started

(1) searching for numbers
(2) searching for integer ranges

Emacs function (re-search-forward)
specify a RE and will search forward until Emacs find a match

  (re-search-forward "ab*c")

add function 'num-search-forward'

  number: [+-]?[0-9]+ (dependent on base)
  hex digits: [a-f][A-F]

  (num-search-forward 239)

    xyabd239efg
    ^  ->  ^

  string representation is not necessary equal to chars in the source code
  do matching with character matching in string, instead of matching number

may want to do approximate search (number range search)
  
  (num-search-forward 239 [250])

  (num-search-forward NUM &optional NUM2 BASE)
  
  two arguments will allow Emacs to search in range of two numbers, inclusive
  BASE is between 2-16, default is 10
  NUM2 and BASE are both optional
  if there is overflow in text, just ignore

    (num-search-forward 239)

      abcd2399128928379827349822934def0239ghi
                                      ^

talking of overflow
(this a good test case)

  (num-search-forward most-negative-fixnum most-positive-fixnum)
                      -2^62                2^62 - 1

for a range search we can transform the search into the original RE functions

buffers are named strings that we are editing
buffers are big
can change and extend buffers
more heavy weight than strings

visit a file
takes all contents and writes to buffer
when we modify file we are actually modifying buffer

to find the current buffer position use

  (point)

this is where to start searching from
searching will change points



** worth 10% of Emacs grade, 2% of total grade
   due Friday Mar. 8, 2016

should be written in Emacs Lisp
put in file num.el

  (defun num-search-forward ...)

this homework is inspired by 'agrep'

to run the file num.el

  M-x load-file RET
  num.el RET


RE search
----------
DFAs
single-character
fast fixed-string search

  $ grep -F 'ab*c'  # simple string matching

-F specifies that the string is not a RE but a fixed string
this can be implemented faster than RE search

Boyer-Moore string search algorithm
------------------------------------
1. searching for a string of known size
   look at the last character of the pattern first

   performance assumptions
   (1) assume pattern is short, string is long
   (2) matches are rare

   p    abcdef
   s    --------------------------------
             ^
             start from here and see if it is a 'f'

2. when you see a failure, figure out where to jump to next
   failures let you jump ahead

   p    abcdef
   s    --------------------------------
             ^
             suppose it's 'g', then we can jump forward 6 chars
             suppose it's 'b', then we can jump forward 3 chars


what can slow down regular expression searching?
-------------------------------------------------
bytes vs characters

  BCDIC (BCD)
    6-bit code (manufacture specific)
    need translate table to copy from one machine to another
  
  EBCDIC (IBM)
    8-bit code
    wasn't quite standardized

  ASCII (everybody else)
    7-bit code
    extra bit as parady bit for catching transmission errors
    eventually 'won'
    enough for most of English, but not all of it
    missing "" '' with directions
    can't do 'naive' with the i with two dots
    not good enough for foreign languages, e.g. French
    8-bit code (256 chars) would not work

  ISO 8859-1 (8-bit ASCII extension)
    covered many western European languages
  ISO 8859-2
  ISO 8859-5
    cyrillic
  ISO 8859-15
    like -1, except for adding a Euro symbol

  case-folded search
    upper case and lower case dit not match in every encoding
    case folding is encoding dependent
    case folding is also language dependent

unibyte encodings (behavior is language and encoding specific)
  more than 256 chars
  16-bit chars, 65536 chars (code points) (Unicode, 1990s)
  font difference, language difference
  the second issue is that 16-bit chars are not large enough
  -> 32-bit chars

byte-encoding for > 256 chars
multibyte characters, single character but more than 1 8-bit char to represent

(1) Shift-JIS
    ASCII chars as themselves
    if first byte is not ASCII, then next byte is treated as payload,
    so this char is represented as a 2 byte char
    however, second byte might be ASCII char, so when searching, we may not
    have found the first byte but simply treated second byte as ASCII

(2) ISO-2022-JP
    switch character sets
    ESC [JC]
    have a lot of flexibility
    still have same problem as (1) does
    suppose we want to apply binary search to text
    this is not possible for 2022 we have to look at all escape sequences
    through the whole string to determine the character set

(3) UTF-8
    multibyte character has payload of trailing bytes (preceded by 10)
    first byte preceded by 11
    byte with leading 0 is ASCII
    
    +-+----+
    |0|    |    ASCII
    +-+----+

    +--+---+--+---+--+---+
    |11|   |10|   |10|   |  ordinary UTF-8 characters
    +--+---+--+---+--+---+

problems in UTF-8
------------------
(1) can be multiple representations for same character
    strcmp doesn't work, since it works on byte level

    UTF-8 simply disallows it currently
    must use shorter version if it exists

(2) encoding errors
    +--------+
    |10000000|   invalid encoding, not a text file!
    +--------+
       128

** READ ABOUT mbrtowc


=============
Apr. 5, 2016
=============

#include <wchar.h>
size_t mbrtowc (wchar_t *restrict pwc, char const *restrict s,
                size_t n, mbstate_t *restrict ps);

char const *restrict s       start of buffer
              size_t n       number of bytes in buffer
mbstate_t *restrict ps       multibyte conversion state
                             converts to ISO-2-22 & etc
 wchar_t *restrict pwc       result (16/32-bit)

            s|<----------------- n ---------------->|
+------------+-+-+-+-+-+----------------------------+
|            | | | | | |                            |
+------------+-+-+-+-+-+----------------------------+
             |<----->|
               bytes consumed

               returns       total number of bytes consumed
                             
                             1-n  # bytes consumed
                             0    NULL char (interface botch, use strlen?)
                             -2   incomplete char
                                  sequence of bytes that may be valid but
                                  we have run off end of the buffer
                             -1   encoding error (what to do?)
                                  fall over and die
                                  flags can say what to do with encoding errors

                                  In RE matching:
                                  (1) encoding error in string is never
                                      matched with anything, encoding errors
                                      in patterns are syntax errors
                                  (2) they're always an error
                                  (3) treating encoding errors as valid
                                      extend to handle other encodings correct
                                      encoding errors are characters
                                      RE matching can match encoding errors

* restrict: pointer with restrict: whenever code accesses pointer, the pointer
  must be independent of others, that is to say, pointers should not point to
  overlapping memory locations
  important for performance

+----------+-+   +-+---------------+
| 200 char | |   | |    300 char   |
+----------+|+   +|+---------------+
   file1    |     |    file2
            |     |
         encoding error

$ cat file1 file2 > file3

+-----------------+--+---------------------+
|     200 char    |  |       300 char      |
+-----------------+--+---------------------+
                  valid char    

maybe file should be sequences of wchar_t? (MS-Windows)
+ simple encoding, decoding
- more space (secondary storage, memory buffer space)
- incompatible with ASCII, Shif-JIS, EUC

mbrtowc is generic, should work for Shif-JIS or any encoding
Locales: context for behaviors that were originally Unix English,
         but need to be more general

char *setlocale (int category, char const *locale);
e.g. setlocale (LC_CTYPE, "en_US.utf8")
                           language_country.encoding

LC_CTYPE      iswalpha, [[:alpha:]]
LC_COLLATE    strcoll, single letters in Spanish: ll, ch
LC_TIME       date
LC_NUMERIC    strtol_l (...,locale)
LC_MESSAGES   strerror (errno)


locale_t newlocale (int categories, char const *locale, locale_t base);

CATEGORIES set of cateogry values
starts off with BASE locale
change the CATEGORIES in BASE to be the new LOCALE
construct new locale that does that and return it

locale_t uselocale (locale_t l);

set the thread's locale to be 'l'
assumes thread local storage (TLS)

locales are heavy-weight and it would be good for the system to cache commonly
used locales.


different ways to specify regular expressions
----------------------------------------------
(1) globbing
    
    simple, fast, specialized for file names & directories

    char        matches itself         a?b.h
    ?           any 1 char             a?b.h
    [abc]       a or b or c  (1 char)  a[a-z]b.h
    *           zero or more chars     a*b.h

      int glob (char const *restrict pattern, int flags,
                int (*errfunc) (char const *, int),
                glob_t *restrict pglob);

      heavy-weight unbounded work

      pattern    null terminated string, "a?b.h"
      errfunc    error handling function callback
      glob_t     struct {
                   size_t gl_pathc;  //
                   char **gl_pathv;
                 }

(2) POSIX BREs (Basic Regular Expressions)

    most commonly used regular expressions
    used by grep

    BRE patterns      what they match
    ---------------------------------------------------------------------------
    c                 c
    \c                always c evey if c is special (does not work in ranges)
    .                 any char except NULL '\0'
    [abc]             set of single chars (256 bits to represent)
    [^abc]            negated set
    [a-zA-Z]          ranges of characters
    [ab\]             backslash not special
    [ab-]             special if at beginning/end
    [#--?]            starting with 'a' ending with '-'
    [z-a]             * undefined behavior
    [[:alnum:]#?:]    any alpha-numeric char, or any #?:
    [abc^]            '^' is not special now
    [[:alnum:]-#]     * undefined behavior
    [[=a=]]           same equivalence class as 'a' (locale dependent set)
    [[abc]            character set of [abc
    [^]ab]            negated set of ]ab
    XY                concatenations
    \(X\)             X
    X*                0 or more instances
    X\{27\}           exactly 27 instances of X
    X\{27,\}          27 or more instances of X
    X\{27,39\}        27 to 39 instances of X
    ^X                X but only at start of string
    X$                X but only at end of string
    \3                back reference to 3rd parenthesized subexpression
    [[.a.]]           matches simply a

    \([abc][def]*\)[^f]*\1

    precedence: *
                concatenation
                anchors (^$)
    ^ab*c

    a^b  (error)
    a\^b (valid)

    
    can be implemented with NFA-DFA

    matcher implementations
    simplest
      backtracking matcher
    DFA
      must have an escape hatch to match \3
      record earlier matches

      sed s/\(a.*b\)a\(a.*b\)/\1q\2/

      have to know where is the match
      where are the submatches

      longest-leftmost
      pattern XYZ

      +--+-----+-----+-----+
      |  |  X  |  Y  |  Z  |
      +--+-----+-----+-----+

      should we maximize length of X or Y or Z
      which alternate to return?
      (1) X is greedy, find the longest X and apply recursively
          leftmost first
          "obvious"
      (2) Z is generous, find the shortest Z
          strange
          most efficient
          arguable POSFIX


** READ Chapters 1-4 (Newman)


























